{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk2Space Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tool import *\n",
    "from utils.config import cfg, loadArgums\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import scanpy\n",
    "from scipy.optimize import nnls\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global args \n",
    "args = dict(\n",
    "    BetaVAE_H=True,\n",
    "    batch_size=512,\n",
    "    cell_num=10,\n",
    "    data_path='example_data/demo1',\n",
    "    dump_path='/data/zhuangxiang/code/bulk2space/bulk2space/dump',\n",
    "    early_stop=50,\n",
    "    epoch_num=500,\n",
    "    exp_id='LR_0.0001_hiddenSize_256_lay_choice_0',\n",
    "    exp_name='test1',\n",
    "    feature_size=6588,\n",
    "    gpu_id=0,\n",
    "    hidden_lay=0,\n",
    "    hidden_size=256,\n",
    "    input_bulk_path='/data/zhuangxiang/code/bulk2space/bulk2space/data/example_data/demo1/demo1_bulk.csv',\n",
    "    input_sc_data_path='/data/zhuangxiang/code/bulk2space/bulk2space/data/example_data/demo1/demo1_sc_data.csv',\n",
    "    input_sc_meta_path='/data/zhuangxiang/code/bulk2space/bulk2space/data/example_data/demo1/demo1_sc_meta.csv',\n",
    "    input_st_data_path='/data/zhuangxiang/code/bulk2space/bulk2space/data/example_data/demo1/demo1_st_data.csv',\n",
    "    input_st_meta_path='/data/zhuangxiang/code/bulk2space/bulk2space/data/example_data/demo1/demo1_st_meta.csv',\n",
    "    k=10, kl_loss=False, learning_rate=0.0001, load_model_1=False, load_path_1='/data/zhuangxiang/code/bulk2space/bulk2space/save_model/',\n",
    "    load_path_2='/data/zhuangxiang/code/bulk2space/bulk2space/save_model/', marker_used=True, max_cell_in_diff_spot_ratio=None, model_choice_1='vae', model_choice_2='df',\n",
    "    mul_test=5, mul_train=1, no_tensorboard=False, not_early_stop=False, num_workers=12, output_path='/data/zhuangxiang/code/bulk2space/bulk2space/output_data',\n",
    "    previous_project_name='demo', project_name='test1', random_seed=12345, ratio_num=1,\n",
    "    save='/data/zhuangxiang/code/bulk2space/bulk2space/save_model', spot_data=True, spot_num=500,\n",
    "    top_marker_num=500, train_model_2=True, xtest='xtest', xtrain='xtrain', ytest='ytest', ytrain='ytrain'\n",
    ")\n",
    "args = argparse.Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data......\n",
      "load data ok\n"
     ]
    }
   ],
   "source": [
    "input_sc_meta_path = args.input_sc_meta_path\n",
    "input_sc_data_path = args.input_sc_data_path\n",
    "input_bulk_path = args.input_bulk_path\n",
    "input_st_meta_path = args.input_st_meta_path\n",
    "input_st_data_path = args.input_st_data_path\n",
    "print(\"loading data......\")\n",
    "\n",
    "# load sc_meta.csv file, containing two columns of cell name and cell type\n",
    "input_sc_meta = pd.read_csv(input_sc_meta_path, index_col=0)\n",
    "# load sc_data.csv file, containing gene expression of each cell\n",
    "input_sc_data = pd.read_csv(input_sc_data_path, index_col=0)\n",
    "sc_gene = input_sc_data._stat_axis.values.tolist()\n",
    "# load bulk.csv file, containing one column of gene expression in bulk\n",
    "input_bulk = pd.read_csv(input_bulk_path, index_col=0)\n",
    "bulk_gene = input_bulk._stat_axis.values.tolist()\n",
    "# filter overlapping genes.\n",
    "intersect_gene = list(set(sc_gene).intersection(set(bulk_gene)))\n",
    "input_sc_data = input_sc_data.loc[intersect_gene]\n",
    "input_bulk = input_bulk.loc[intersect_gene]\n",
    "# load st_meta.csv and st_data.csv, containing coordinates and gene expression of each spot respectively.\n",
    "input_st_meta = pd.read_csv(input_st_meta_path, index_col=0)\n",
    "input_st_data = pd.read_csv(input_st_data_path, index_col=0)\n",
    "print(\"load data ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = scanpy.AnnData(input_sc_data.T)\n",
    "sc.obs = input_sc_meta[['Cell_type']]\n",
    "scanpy.tl.rank_genes_groups(sc, 'Cell_type', method='wilcoxon')\n",
    "marker_df = pd.DataFrame(sc.uns['rank_genes_groups']['names']).head(args.top_marker_num)\n",
    "marker_array = np.array(marker_df)\n",
    "marker_array = np.ravel(marker_array)\n",
    "marker_array = np.unique(marker_array)\n",
    "marker = list(marker_array)\n",
    "sc_marker = input_sc_data.loc[marker, :]\n",
    "bulk_marker = input_bulk.loc[marker]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed = input_sc_meta['Cell_type']\n",
    "breed_np = breed.values\n",
    "breed_set = set(breed_np)\n",
    "id2label = sorted(list(breed_set))  # List of breed\n",
    "label2id = {label: idx for idx, label in enumerate(id2label)}  # map breed to breed-id\n",
    "\n",
    "cell2label = dict()  # map cell-name to breed-id\n",
    "label2cell = defaultdict(set)  # map breed-id to cell-names\n",
    "for row in input_sc_meta.itertuples():\n",
    "    cell_name = getattr(row, 'Cell')\n",
    "    cell_type = label2id[getattr(row, 'Cell_type')]\n",
    "    cell2label[cell_name] = cell_type\n",
    "    label2cell[cell_type].add(cell_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_devide_data = dict()\n",
    "for label, cells in label2cell.items():\n",
    "    label_devide_data[label] = sc_marker[list(cells)]\n",
    "\n",
    "single_cell_splitby_breed_np = {}\n",
    "for key in label_devide_data.keys():\n",
    "    single_cell_splitby_breed_np[key] = label_devide_data[key].values  # [gene_num, cell_num]\n",
    "    single_cell_splitby_breed_np[key] = single_cell_splitby_breed_np[key].mean(axis=1)\n",
    "\n",
    "max_decade = len(single_cell_splitby_breed_np.keys())\n",
    "single_cell_matrix = []\n",
    "#\n",
    "for i in range(max_decade):\n",
    "    single_cell_matrix.append(single_cell_splitby_breed_np[i].tolist())\n",
    "\n",
    "\n",
    "single_cell_matrix = np.array(single_cell_matrix)\n",
    "single_cell_matrix = np.transpose(single_cell_matrix)  # (gene_num, label_num)\n",
    "\n",
    "bulk_marker = bulk_marker.values  # (gene_num, 1)\n",
    "bulk_rep = bulk_marker.reshape(bulk_marker.shape[0],)\n",
    "\n",
    "# calculate celltype ratio in each spot by NNLS\n",
    "ratio = nnls(single_cell_matrix, bulk_rep)[0]\n",
    "ratio = ratio/sum(ratio)\n",
    "\n",
    "ratio_array = np.round(ratio * input_sc_meta.shape[0] * args.ratio_num)\n",
    "ratio_list = [r for r in ratio_array]\n",
    "\n",
    "# pdb.set_trace()\n",
    "cell_target_num = dict(zip(id2label, ratio_list))\n",
    "\n",
    "# *********************************************************************\n",
    "# input：data， celltype， bulk & output: label, dic, single_cell\n",
    "single_cell = input_sc_data.values.T  # single cell data (600 * 6588)\n",
    "index_2_gene = (input_sc_data.index).tolist()\n",
    "breed = input_sc_meta['Cell_type']\n",
    "breed_np = breed.values\n",
    "breed_set = set(breed_np)\n",
    "breed_2_list = list(breed_set)\n",
    "dic = {}  # breed_set to index {'B cell': 0, 'Monocyte': 1, 'Dendritic cell': 2, 'T cell': 3}\n",
    "label = []  # the label of cell (with index correspond)\n",
    "cfg.nclass = len(breed_set)\n",
    "\n",
    "cfg.ntrain = single_cell.shape[0]\n",
    "cfg.FeaSize = single_cell.shape[1]\n",
    "args.feature_size = single_cell.shape[1]\n",
    "assert cfg.nclass == len(cell_target_num.keys()), \"cell type num no match!!!\"\n",
    "\n",
    "for i in range(len(breed_set)):\n",
    "    dic[breed_2_list[i]] = i\n",
    "cell = input_sc_meta[\"Cell\"].values\n",
    "\n",
    "for i in range(cell.shape[0]):\n",
    "    label.append(dic[breed_np[i]])\n",
    "\n",
    "label = np.array(label)\n",
    "\n",
    "# label index the data size of corresponding target\n",
    "cell_number_target_num = {}\n",
    "for k, v in cell_target_num.items():\n",
    "    cell_number_target_num[dic[k]] = v\n",
    "# pdb.set_trace()\n",
    "# *********************************************************************\n",
    "# generate data by vae\n",
    "load_model_1 = args.load_model_1\n",
    "model_choice_1 = args.model_choice_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin vae model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 499: 100%|██████████| 500/500 [05:48<00:00,  1.44it/s, loss=0.4561, min_loss=0.4558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min loss = 0.4557696580886841\n",
      "vae training finished!\n"
     ]
    }
   ],
   "source": [
    "ratio = -1\n",
    "if not load_model_1:  # train\n",
    "    print(\"begin vae model training...\")\n",
    "    # ********************* training *********************\n",
    "    net = train_vae(args, single_cell, cfg, label)\n",
    "    # ************** training finished *******************\n",
    "    print(\"vae training finished!\")\n",
    "else:  # load model\n",
    "    print(\"begin vae model loading...\")\n",
    "    net = load_vae(args, cfg)\n",
    "    print(\"vae load finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate Epoch: 3: 100%|██████████| 249/249.0 [00:02<00:00, 91.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated done!\n",
      "begin data to spatial mapping...\n",
      "Data have been prepared...\n",
      "bulk deconvolution finish!\n",
      "start to map data to space...\n"
     ]
    }
   ],
   "source": [
    "# generate and out put\n",
    "generate_sc_meta, generate_sc_data = generate_vae(net, args, ratio, single_cell, cfg, label, breed_2_list, index_2_gene, cell_number_target_num)\n",
    "\n",
    "\n",
    "# saving.....\n",
    "path = osp.join(args.output_path, args.project_name, 'predata')\n",
    "if not osp.exists(path):\n",
    "    os.makedirs(path)\n",
    "name = \"vae\"\n",
    "# kl_loss BetaVAE_H\n",
    "if args.BetaVAE_H:\n",
    "    name = \"BetaVAE\"\n",
    "path_label_generate_csv = os.path.join(path, args.project_name + \"_celltype_pred_\" + name + \"_epoch\" + str(args.epoch_num) + '_lr' + str(args.learning_rate) + \".csv\")\n",
    "path_cell_generate_csv = os.path.join(path, args.project_name + \"_data_pred_\" + name + \"_epoch\" + str(args.epoch_num) + '_lr' + str(args.learning_rate) + \".csv\")\n",
    "\n",
    "generate_sc_meta.to_csv(path_label_generate_csv)\n",
    "generate_sc_data.to_csv(path_cell_generate_csv)\n",
    "\n",
    "print(\"bulk deconvolution finish!\")\n",
    "\n",
    "print('start to map data to space...')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a80fd7de3d2327e4562cce3df74611e7327e3f8b020db5edf85472319b8753a2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
